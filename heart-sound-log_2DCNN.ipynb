{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fed409f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-15 10:57:13.940638: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-03-15 10:57:13.940743: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_107/773148935.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \"\"\"\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_typing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# from tensorflow.python import keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfeature_column_lib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfeature_column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;31m# from tensorflow.python.layers import layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/feature_column/feature_column_lib.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# pylint: disable=unused-import,line-too-long,wildcard-import,g-bad-import-order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column_v2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence_feature_column\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/feature_column/feature_column.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msparse_tensor\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msparse_tensor_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# =============================================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\"\"\"Contains the base Layer class, from which all layers inherit.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_tf_layers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mInputSpec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInputSpec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# See b/110718070#comment18 for more details about this import.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmetrics_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizer_v1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute_coordinator_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/backend_config.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mkeras_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'keras.backend.epsilon'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_dispatch_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m   \"\"\"Returns the value of the fuzz factor used in numeric expressions.\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36madd_dispatch_support\u001b[0;34m(target, iterable_parameters)\u001b[0m\n\u001b[1;32m   1101\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mdecorator\u001b[0;34m(dispatch_target)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     op_dispatch_handler = tf_decorator.make_decorator(dispatch_target,\n\u001b[1;32m   1094\u001b[0m                                                       op_dispatch_handler)\n\u001b[0;32m-> 1095\u001b[0;31m     \u001b[0madd_type_based_api_dispatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1096\u001b[0m     api_dispatcher = getattr(op_dispatch_handler, TYPE_BASED_DISPATCH_ATTR,\n\u001b[1;32m   1097\u001b[0m                              None)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36madd_type_based_api_dispatcher\u001b[0;34m(target)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m   \u001b[0mtarget_argspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_inspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munwrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtarget_argspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvarargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtarget_argspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;31m# @TODO(b/194903203) Add v2 dispatch support for APIs that take varargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/tf_inspect.py\u001b[0m in \u001b[0;36mgetargspec\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;31m# Python3 will handle most callables here (not partial).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_getargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/tf_inspect.py\u001b[0m in \u001b[0;36m_getargspec\u001b[0;34m(target)\u001b[0m\n\u001b[1;32m     79\u001b[0m       \u001b[0;32mfrom\u001b[0m \u001b[0mFullArgSpec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \"\"\"\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mfullargspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     argspecs = ArgSpec(\n\u001b[1;32m     83\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfullargspecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/tf_inspect.py\u001b[0m in \u001b[0;36mgetfullargspec\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator_argspec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_convert_maybe_argspec_to_fullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator_argspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_getfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/inspect.py\u001b[0m in \u001b[0;36mgetfullargspec\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m   1160\u001b[0m         \u001b[0;31m# so we ensure that remains the case in 3.3+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1162\u001b[0;31m         sig = _signature_from_callable(func,\n\u001b[0m\u001b[1;32m   1163\u001b[0m                                        \u001b[0mfollow_wrapper_chains\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m                                        \u001b[0mskip_bound_arg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/inspect.py\u001b[0m in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, sigcls)\u001b[0m\n\u001b[1;32m   2323\u001b[0m         \u001b[0;31m# If it's a pure Python function, or an object that is duck type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2324\u001b[0m         \u001b[0;31m# of a Python function (Cython functions, for instance), then:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2325\u001b[0;31m         return _signature_from_function(sigcls, obj,\n\u001b[0m\u001b[1;32m   2326\u001b[0m                                         skip_bound_arg=skip_bound_arg)\n\u001b[1;32m   2327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/inspect.py\u001b[0m in \u001b[0;36m_signature_from_function\u001b[0;34m(cls, func, skip_bound_arg)\u001b[0m\n\u001b[1;32m   2239\u001b[0m     \u001b[0;31m# Is 'func' is a pure Python function - don't validate the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2240\u001b[0m     \u001b[0;31m# parameters list (for correct order and defaults), it should be OK.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2241\u001b[0;31m     return cls(parameters,\n\u001b[0m\u001b[1;32m   2242\u001b[0m                \u001b[0mreturn_annotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mannotations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'return'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_empty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2243\u001b[0m                __validate_parameters__=is_duck_function)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/inspect.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, parameters, return_annotation, __validate_parameters__)\u001b[0m\n\u001b[1;32m   2828\u001b[0m                     \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2829\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2830\u001b[0;31m                 \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2832\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMappingProxyType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/inspect.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2828\u001b[0m                     \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2829\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2830\u001b[0;31m                 \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2832\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMappingProxyType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Audio\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "# Scikit learn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score, matthews_corrcoef\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import plot_confusion_matrix as sk_plot_confusion_matrix\n",
    "\n",
    "# Keras\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "\n",
    "\n",
    "# TensorFlow\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "dataset = []\n",
    "for folder in [\"Heartbeat_Sounds/set_a/**\",\"Heartbeat_Sounds/set_b/**\"]:\n",
    "    for filename in glob.iglob(folder):\n",
    "        if os.path.exists(filename):\n",
    "            label = os.path.basename(filename).split(\"_\")[0]\n",
    "            duration = librosa.get_duration(filename=filename)\n",
    "            # skip audio smaller than 3 secs\n",
    "            if duration>=3:\n",
    "                slice_size = 3\n",
    "                iterations = int((duration-slice_size)/(slice_size-1))\n",
    "                iterations += 1\n",
    "#                 initial_offset = (duration % slice_size)/2\n",
    "                initial_offset = (duration - ((iterations*(slice_size-1))+1))/2\n",
    "                if label not in [\"Aunlabelledtest\", \"Bunlabelledtest\"]:\n",
    "                    for i in range(iterations):\n",
    "                        offset = initial_offset + i*(slice_size-1)\n",
    "                        \n",
    "                        dataset.append({\n",
    "                                \"filename\": filename,\n",
    "                                \"label\": label,\n",
    "                                \"offset\": offset\n",
    "                            })\n",
    "                       \n",
    "                        \n",
    "dataset = pd.DataFrame(dataset)\n",
    "dataset = shuffle(dataset, random_state=42)\n",
    "dataset.info()\n",
    "\n",
    "# Function to extract features\n",
    "def extract_features(audio_path, offset):\n",
    "    y, sr = librosa.load(audio_path, offset=offset, duration=3)\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=512, n_mels=128)\n",
    "    mfccs = librosa.feature.mfcc(S=librosa.power_to_db(S), n_mfcc=40)\n",
    "    return mfccs\n",
    "\n",
    "# Extract features for all data points\n",
    "x_data = []\n",
    "for idx in tqdm(range(len(dataset))):\n",
    "    mfccs = extract_features(dataset.filename.iloc[idx], dataset.offset.iloc[idx])\n",
    "    # Reshape the 2D array to 3D array\n",
    "    mfccs = mfccs.reshape((mfccs.shape[0], mfccs.shape[1], 1))\n",
    "    x_data.append(mfccs)\n",
    "\n",
    "# Convert to numpy array\n",
    "x_data = np.asarray(x_data)\n",
    "\n",
    "\n",
    "# Encode Labels\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataset.label)\n",
    "y_data = encoder.transform(dataset.label)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = class_weight.compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_data), y=y_data)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_data_one_hot = to_categorical(y_data)\n",
    "\n",
    "# Initialize StratifiedKFold with train_size and test_size\n",
    "kfold = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize lists to store results for each fold\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "train_auc_scores = []\n",
    "test_auc_scores = []\n",
    "train_mcc_scores = []\n",
    "test_mcc_scores = []\n",
    "train_conf_matrices = []\n",
    "test_conf_matrices = []\n",
    "train_class_reports = []\n",
    "test_class_reports = []\n",
    "cm_test_normalized = []\n",
    "report_test_list = []\n",
    "cm_test_normalized_list = []\n",
    "\n",
    "# Open the common results file in 'w' mode to overwrite existing content\n",
    "with open('results_heartSound/all_folds_2dcnn5_results.txt', 'w') as common_file:\n",
    "    # Split the indices instead of the dataset\n",
    "    for fold, (train_index, test_index) in enumerate(kfold.split(x_data, y_data), 1):\n",
    "        x_train_fold, x_test_fold = x_data[train_index], x_data[test_index]\n",
    "        y_train_fold, y_test_fold = y_data_one_hot[train_index], y_data_one_hot[test_index]\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(filters=32, kernel_size=2, input_shape=(x_train_fold.shape[1], x_train_fold.shape[2], x_train_fold.shape[3]), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=2))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Conv2D(filters=64, kernel_size=2, activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=2))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Conv2D(filters=128, kernel_size=2, activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=2))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Conv2D(filters=256, kernel_size=2, activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=2))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(GlobalAveragePooling2D())\n",
    "\n",
    "        model.add(Dense(len(encoder.classes_), activation='softmax'))\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        your_epochs = 100  # You can choose an appropriate number of epochs\n",
    "        your_batch_size = 64  # You can choose an appropriate batch size\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(x_train_fold, y_train_fold, epochs=your_epochs, batch_size=your_batch_size, verbose=1)\n",
    "\n",
    "        # Evaluate on train and test sets\n",
    "        y_pred_train = model.predict(x_train_fold)\n",
    "        y_pred_test = model.predict(x_test_fold)\n",
    "        \n",
    "        # Generate classification report and confusion matrix for test set\n",
    "        y_pred_test_labels = np.argmax(y_pred_test, axis=1)\n",
    "        report_test = classification_report(np.argmax(y_test_fold, axis=1), y_pred_test_labels, output_dict=True)\n",
    "\n",
    "\n",
    "        # Calculate metrics for train set\n",
    "        train_accuracy = accuracy_score(np.argmax(y_train_fold, axis=1), np.argmax(y_pred_train, axis=1))\n",
    "        train_auc = roc_auc_score(y_train_fold, y_pred_train, multi_class='ovr')\n",
    "        train_mcc = matthews_corrcoef(np.argmax(y_train_fold, axis=1), np.argmax(y_pred_train, axis=1))\n",
    "        train_cm = confusion_matrix(np.argmax(y_train_fold, axis=1), np.argmax(y_pred_train, axis=1))\n",
    "        train_class_report = classification_report(np.argmax(y_train_fold, axis=1), np.argmax(y_pred_train, axis=1),\n",
    "                                                   target_names=encoder.classes_)\n",
    "\n",
    "        # Calculate metrics for test set\n",
    "        test_accuracy = accuracy_score(np.argmax(y_test_fold, axis=1), np.argmax(y_pred_test, axis=1))\n",
    "        test_auc = roc_auc_score(y_test_fold, y_pred_test, multi_class='ovr')\n",
    "        test_mcc = matthews_corrcoef(np.argmax(y_test_fold, axis=1), np.argmax(y_pred_test, axis=1))\n",
    "        test_cm = confusion_matrix(np.argmax(y_test_fold, axis=1), np.argmax(y_pred_test, axis=1))\n",
    "        test_class_report = classification_report(np.argmax(y_test_fold, axis=1), np.argmax(y_pred_test, axis=1),\n",
    "                                                  target_names=encoder.classes_)\n",
    "\n",
    "        # Inside the loop where you append accuracies to lists\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "\n",
    "        # Calculate std for train and test accuracies\n",
    "        train_accuracy_std = np.std(train_accuracies)\n",
    "        test_accuracy_std = np.std(test_accuracies)\n",
    "\n",
    "\n",
    "        # Save results to the common text file for both train and test sets\n",
    "        common_file.write(f'Fold {fold} Results:\\n')\n",
    "        common_file.write(f'Train Accuracy: {train_accuracy} (std: {train_accuracy_std})\\n')\n",
    "        common_file.write(f'Train AUC Score: {train_auc}\\n')\n",
    "        common_file.write(f'Train MCC Score: {train_mcc}\\n\\n')\n",
    "        common_file.write('Train Confusion Matrix:\\n')\n",
    "        common_file.write(str(train_cm))\n",
    "        common_file.write('\\n\\nTrain Classification Report:\\n')\n",
    "        common_file.write(train_class_report)\n",
    "\n",
    "        common_file.write(f'\\n\\nTest Accuracy: {test_accuracy} (std: {test_accuracy_std})\\n')\n",
    "        common_file.write(f'Test AUC Score: {test_auc}\\n')\n",
    "        common_file.write(f'Test MCC Score: {test_mcc}\\n\\n')\n",
    "        common_file.write('Test Confusion Matrix:\\n')\n",
    "        common_file.write(str(test_cm))\n",
    "        common_file.write('\\n\\nTest Classification Report:\\n')\n",
    "        common_file.write(test_class_report)\n",
    "        \n",
    "        # Print a separator between folds\n",
    "        common_file.write(\"\\n\" + \"=\"*40 + \"\\n\")\n",
    "        \n",
    "        # Calculate average metrics for train set\n",
    "        avg_train_accuracy = np.mean(train_accuracies)\n",
    "        avg_train_auc = np.mean(train_auc_scores)\n",
    "        avg_train_mcc = np.mean(train_mcc_scores)\n",
    "        avg_train_conf_matrix = np.mean(train_conf_matrices, axis=0)  # Average confusion matrix\n",
    "\n",
    "        # Convert continuous probabilities to class labels using argmax\n",
    "        y_pred_train_class = np.argmax(y_pred_train, axis=1)\n",
    "\n",
    "        # Calculate average metrics for test set\n",
    "        avg_test_accuracy = np.mean(test_accuracies)\n",
    "        avg_test_auc = np.mean(test_auc_scores)\n",
    "        avg_test_mcc = np.mean(test_mcc_scores)\n",
    "        avg_test_conf_matrix = np.mean(test_conf_matrices, axis=0)  # Average confusion matrix\n",
    "\n",
    "        # Convert continuous probabilities to class labels using argmax\n",
    "        y_pred_test_class = np.argmax(y_pred_test, axis=1)\n",
    "        \n",
    "        # Calculate average results for train set\n",
    "        avg_train_class_report = classification_report(np.argmax(y_train_fold, axis=1), y_pred_train_class, target_names=encoder.classes_)\n",
    "\n",
    "        # Calculate average results for test set\n",
    "        avg_test_class_report = classification_report(np.argmax(y_test_fold, axis=1), y_pred_test_class, target_names=encoder.classes_)\n",
    "\n",
    "        # Inside the loop where you plot confusion matrices\n",
    "        plt.figure()\n",
    "        train_cm = confusion_matrix(np.argmax(y_train_fold, axis=1), y_pred_train.argmax(axis=1))\n",
    "\n",
    "        # Round each value in the confusion matrix to 5 decimal places\n",
    "        rounded_train_cm = np.round(train_cm / np.sum(train_cm, axis=1)[:, np.newaxis], 5)\n",
    "\n",
    "        sns.heatmap(rounded_train_cm, annot=True, fmt='.5f', cmap='Blues', xticklabels=encoder.classes_, yticklabels=encoder.classes_)\n",
    "        plt.title(f'Train Confusion Matrix - Fold {fold}')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.savefig(f'2DCNN/train_confusion_matrix_fold_{fold}.png')\n",
    "        plt.close()\n",
    "\n",
    "        # Inside the loop where you plot confusion matrices\n",
    "        plt.figure()\n",
    "        test_cm = confusion_matrix(np.argmax(y_test_fold, axis=1), y_pred_test.argmax(axis=1))\n",
    "\n",
    "        # Round each value in the confusion matrix to 5 decimal places\n",
    "        rounded_test_cm = np.round(test_cm / np.sum(test_cm, axis=1)[:, np.newaxis], 5)\n",
    "\n",
    "        sns.heatmap(rounded_test_cm, annot=True, fmt='.5f', cmap='Blues', xticklabels=encoder.classes_, yticklabels=encoder.classes_)\n",
    "        plt.title(f'Test Confusion Matrix - Fold {fold}')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.savefig(f'2DCNN/test_confusion_matrix_fold_{fold}.png')\n",
    "        plt.close()\n",
    "\n",
    "        # Inside the loop where you append results to lists\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        train_auc_scores.append(train_auc)\n",
    "        test_auc_scores.append(test_auc)\n",
    "        train_mcc_scores.append(train_mcc)\n",
    "        test_mcc_scores.append(test_mcc)\n",
    "        train_conf_matrices.append(train_cm)\n",
    "        test_conf_matrices.append(test_cm)\n",
    "        train_class_reports.append(train_class_report)\n",
    "        test_class_reports.append(test_class_report)\n",
    "        \n",
    "        # Print a separator between folds\n",
    "        common_file.write(\"\\n\" + \"=\"*40 + \"\\n\")\n",
    "        \n",
    "        # Append classification report and confusion matrix to lists\n",
    "        report_test_list.append(report_test)\n",
    "        cm_test_normalized_list.append(cm_test_normalized)\n",
    "\n",
    "    # Calculate average metrics for train set\n",
    "    avg_train_accuracy = np.mean(train_accuracies)\n",
    "    avg_train_auc = np.mean(train_auc_scores)\n",
    "    avg_train_mcc = np.mean(train_mcc_scores)\n",
    "\n",
    "    # Reshape y_train_fold to (num_samples, num_classes)\n",
    "    y_train_fold_reshaped = to_categorical(y_train_fold, num_classes=len(encoder.classes_))\n",
    "\n",
    "    # Convert predictions to one-hot encoding\n",
    "    y_pred_train_one_hot = to_categorical(np.argmax(y_pred_train, axis=1), num_classes=len(encoder.classes_))\n",
    "\n",
    "    # Calculate average confusion matrix for train set\n",
    "    avg_train_conf_matrix = np.mean(train_conf_matrices, axis=0).astype(int)\n",
    "\n",
    "\n",
    "    # Calculate average classification report for train set\n",
    "    avg_train_class_report = classification_report(\n",
    "        np.argmax(y_train_fold, axis=1), \n",
    "        np.argmax(y_pred_train_one_hot, axis=1), \n",
    "        target_names=encoder.classes_, \n",
    "        digits=5\n",
    "    )\n",
    "    \n",
    "\n",
    "    # Calculate average metrics for test set\n",
    "    avg_test_accuracy = np.mean(test_accuracies)\n",
    "    avg_test_auc = np.mean(test_auc_scores)\n",
    "    avg_test_mcc = np.mean(test_mcc_scores)\n",
    "\n",
    "    # Reshape y_test_fold to (num_samples, num_classes)\n",
    "    y_test_fold_reshaped = to_categorical(y_test_fold, num_classes=len(encoder.classes_))\n",
    "\n",
    "    # Convert predictions to one-hot encoding\n",
    "    y_pred_test_one_hot = to_categorical(np.argmax(y_pred_test, axis=1), num_classes=len(encoder.classes_))\n",
    "\n",
    "    # Calculate average confusion matrix for test set\n",
    "    avg_test_conf_matrix = np.mean(test_conf_matrices, axis=0).astype(int)\n",
    "\n",
    "    # Calculate average classification report for test set\n",
    "    avg_test_class_report = classification_report(\n",
    "        np.argmax(y_test_fold, axis=1), \n",
    "        np.argmax(y_pred_test_one_hot, axis=1), \n",
    "        target_names=encoder.classes_, \n",
    "        digits=5\n",
    "    )\n",
    "\n",
    "    # Inside the loop where you plot the average confusion matrix for the test set\n",
    "    avg_cm_test_normalized = np.mean(cm_test_normalized_list, axis=0)\n",
    "    plt.figure()\n",
    "\n",
    "    avg_test_cm = confusion_matrix(np.argmax(y_test_fold, axis=1), np.argmax(y_pred_test, axis=1))\n",
    "\n",
    "    # Normalize the confusion matrix by dividing each value by the sum of its row\n",
    "    normalized_avg_test_cm = avg_test_cm / avg_test_cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    # Plot confusion matrix for the average test set\n",
    "    plt.figure()\n",
    "    sns.heatmap(normalized_avg_test_cm, annot=True, fmt='.5f', cmap='Blues', xticklabels=encoder.classes_, yticklabels=encoder.classes_)\n",
    "    plt.title(f'Average Test Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.savefig('2DCNN/average_test_confusion_matrix.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Save average results to the common text file\n",
    "    common_file.write(\"\\n\" + \"=\"*40 + \"\\n\")\n",
    "    common_file.write(f'Average Test Accuracy: {avg_test_accuracy:.5f} (std: {np.std(test_accuracies):.5f})\\n')\n",
    "    common_file.write(f'Average Test AUC Score: {avg_test_auc:.5f}\\n')\n",
    "    common_file.write(f'Average Test MCC Score: {avg_test_mcc:.5f}\\n\\n')\n",
    "    common_file.write('Average Test Confusion Matrix:\\n')\n",
    "    common_file.write(str(avg_cm_test_normalized.round(5).astype(int)))  # Display confusion matrix with 5 decimal places\n",
    "    common_file.write(\"\\n\\nAverage Test Classification Report:\\n\")\n",
    "    common_file.write(str(avg_test_class_report))\n",
    "\n",
    "\n",
    "    # Print and write the average results to the common text file\n",
    "    common_file.write(\"\\n\" + \"=\"*40 + \"\\n\")\n",
    "    common_file.write(f'Average Test Accuracy: {avg_test_accuracy:.5f} (std: {np.std(test_accuracies):.5f})\\n')\n",
    "    common_file.write(f'Average Test AUC Score: {avg_test_auc:.5f}\\n')\n",
    "    common_file.write(f'Average Test MCC Score: {avg_test_mcc:.5f}\\n\\n')\n",
    "    common_file.write('Average Test Confusion Matrix:\\n')\n",
    "    common_file.write(str(avg_cm_test_normalized.round(5).astype(int)))  # Display confusion matrix with 5 decimal places\n",
    "    common_file.write(\"\\n\\nAverage Test Classification Report:\\n\")\n",
    "    common_file.write(str(avg_test_class_report))\n",
    "\n",
    "\n",
    "    # Print and write the average results to the common text file\n",
    "    common_file.write(\"\\n\" + \"=\"*40 + \"\\n\")\n",
    "    common_file.write(f'Average Train Accuracy: {avg_train_accuracy} (std: {np.std(train_accuracies)})\\n')\n",
    "    common_file.write(f'Average Train AUC Score: {avg_train_auc}\\n')\n",
    "    common_file.write(f'Average Train MCC Score: {avg_train_mcc}\\n\\n')\n",
    "    common_file.write('Average Train Confusion Matrix:\\n')\n",
    "    common_file.write(str(avg_train_conf_matrix.astype(int)))\n",
    "    common_file.write(\"\\n\\nAverage Train Classification Report:\\n\")\n",
    "    common_file.write(str(avg_train_class_report))\n",
    "\n",
    "    common_file.write(\"\\n\" + \"=\"*40 + \"\\n\")\n",
    "    common_file.write(f'Average Test Accuracy: {avg_test_accuracy} (std: {np.std(test_accuracies)})\\n')\n",
    "    common_file.write(f'Average Test AUC Score: {avg_test_auc}\\n')\n",
    "    common_file.write(f'Average Test MCC Score: {avg_test_mcc}\\n\\n')\n",
    "    common_file.write('Average Test Confusion Matrix:\\n')\n",
    "    common_file.write(str(avg_test_conf_matrix.astype(int)))\n",
    "    common_file.write(\"\\n\\nAverage Test Classification Report:\\n\")\n",
    "    common_file.write(str(avg_test_class_report))\n",
    "        \n",
    "    # Print average results for train set\n",
    "    print(f'Average Train Accuracy: {avg_train_accuracy}')\n",
    "    print(f'Average Train AUC Score: {avg_train_auc}')\n",
    "    print(f'Average Train MCC Score: {avg_train_mcc} \\n')\n",
    "    print(\"\\nAverage Train Classification Report:\")\n",
    "    print(avg_train_class_report)\n",
    "\n",
    "    # Print average results for test set\n",
    "    print(f'Average Test Accuracy: {avg_test_accuracy}')\n",
    "    print(f'Average Test AUC Score: {avg_test_auc}')\n",
    "    print(f'Average Test MCC Score: {avg_test_mcc} \\n')\n",
    "    print(\"\\nAverage Test Classification Report:\")\n",
    "    print(avg_test_class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ac88697",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1441 entries, 168 to 1126\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   filename  1441 non-null   object \n",
      " 1   label     1441 non-null   object \n",
      " 2   offset    1441 non-null   float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 45.0+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 1441/1441 [04:58<00:00,  4.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1152/1152 [==============================] - 101s 59ms/step - loss: 1.3304 - accuracy: 0.4696\n",
      "Epoch 2/100\n",
      "1152/1152 [==============================] - 55s 47ms/step - loss: 1.2707 - accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "1152/1152 [==============================] - 55s 48ms/step - loss: 1.2549 - accuracy: 0.5286\n",
      "Epoch 4/100\n",
      "1152/1152 [==============================] - 53s 46ms/step - loss: 1.2444 - accuracy: 0.5252\n",
      "Epoch 5/100\n",
      "1152/1152 [==============================] - 48s 42ms/step - loss: 1.2387 - accuracy: 0.5304\n",
      "Epoch 6/100\n",
      "1152/1152 [==============================] - 43s 37ms/step - loss: 1.2314 - accuracy: 0.5339\n",
      "Epoch 7/100\n",
      "1152/1152 [==============================] - 37s 32ms/step - loss: 1.2331 - accuracy: 0.5339\n",
      "Epoch 8/100\n",
      "1152/1152 [==============================] - 39s 34ms/step - loss: 1.2286 - accuracy: 0.5339\n",
      "Epoch 9/100\n",
      "1152/1152 [==============================] - 38s 33ms/step - loss: 1.2267 - accuracy: 0.5339\n",
      "Epoch 10/100\n",
      "1152/1152 [==============================] - 43s 37ms/step - loss: 1.2286 - accuracy: 0.5339\n",
      "Epoch 11/100\n",
      "1152/1152 [==============================] - 52s 45ms/step - loss: 1.2307 - accuracy: 0.5330\n",
      "Epoch 12/100\n",
      "1152/1152 [==============================] - 43s 37ms/step - loss: 1.2328 - accuracy: 0.5339\n",
      "Epoch 13/100\n",
      "1152/1152 [==============================] - 43s 38ms/step - loss: 1.2261 - accuracy: 0.5339\n",
      "Epoch 14/100\n",
      "1152/1152 [==============================] - 43s 38ms/step - loss: 1.2296 - accuracy: 0.5339\n",
      "Epoch 15/100\n",
      "1152/1152 [==============================] - 43s 37ms/step - loss: 1.2304 - accuracy: 0.5330\n",
      "Epoch 16/100\n",
      "1152/1152 [==============================] - 44s 38ms/step - loss: 1.2308 - accuracy: 0.5339\n",
      "Epoch 17/100\n",
      "1152/1152 [==============================] - 48s 41ms/step - loss: 1.2304 - accuracy: 0.5339\n",
      "Epoch 18/100\n",
      "1152/1152 [==============================] - 42s 36ms/step - loss: 1.2297 - accuracy: 0.5339\n",
      "Epoch 19/100\n",
      "1152/1152 [==============================] - 36s 32ms/step - loss: 1.2251 - accuracy: 0.5339\n",
      "Epoch 20/100\n",
      "1152/1152 [==============================] - 34s 30ms/step - loss: 1.2393 - accuracy: 0.5339\n",
      "Epoch 21/100\n",
      "1152/1152 [==============================] - 34s 30ms/step - loss: 1.2458 - accuracy: 0.5312\n",
      "Epoch 22/100\n",
      "1152/1152 [==============================] - 36s 31ms/step - loss: 1.2371 - accuracy: 0.5339\n",
      "Epoch 23/100\n",
      "1152/1152 [==============================] - 37s 32ms/step - loss: 1.2422 - accuracy: 0.5304\n",
      "Epoch 24/100\n",
      "1152/1152 [==============================] - 36s 31ms/step - loss: 1.2312 - accuracy: 0.5339\n",
      "Epoch 25/100\n",
      "1152/1152 [==============================] - 35s 31ms/step - loss: 1.2282 - accuracy: 0.5339\n",
      "Epoch 26/100\n",
      "1152/1152 [==============================] - 33s 29ms/step - loss: 1.2270 - accuracy: 0.5339\n",
      "Epoch 27/100\n",
      "1152/1152 [==============================] - 29s 25ms/step - loss: 1.2238 - accuracy: 0.5330\n",
      "Epoch 28/100\n",
      "1152/1152 [==============================] - 40s 34ms/step - loss: 1.2284 - accuracy: 0.5330\n",
      "Epoch 29/100\n",
      "1152/1152 [==============================] - 37s 32ms/step - loss: 1.2318 - accuracy: 0.5339\n",
      "Epoch 30/100\n",
      "1152/1152 [==============================] - 47s 41ms/step - loss: 1.2302 - accuracy: 0.5339\n",
      "Epoch 31/100\n",
      "1152/1152 [==============================] - 44s 38ms/step - loss: 1.2338 - accuracy: 0.5339\n",
      "Epoch 32/100\n",
      "1152/1152 [==============================] - 283s 246ms/step - loss: 1.2344 - accuracy: 0.5339\n",
      "Epoch 33/100\n",
      "1152/1152 [==============================] - 83s 72ms/step - loss: 1.2346 - accuracy: 0.5321\n",
      "Epoch 34/100\n",
      "1152/1152 [==============================] - 49s 42ms/step - loss: 1.2347 - accuracy: 0.5339\n",
      "Epoch 35/100\n",
      "1152/1152 [==============================] - 76s 66ms/step - loss: 1.2291 - accuracy: 0.5339\n",
      "Epoch 36/100\n",
      "1152/1152 [==============================] - 53s 46ms/step - loss: 1.2268 - accuracy: 0.5339\n",
      "Epoch 37/100\n",
      "1152/1152 [==============================] - 69s 60ms/step - loss: 1.2270 - accuracy: 0.5339\n",
      "Epoch 38/100\n",
      "1152/1152 [==============================] - 57s 50ms/step - loss: 1.2331 - accuracy: 0.5339\n",
      "Epoch 39/100\n",
      "1152/1152 [==============================] - 80s 69ms/step - loss: 1.2243 - accuracy: 0.5339\n",
      "Epoch 40/100\n",
      "1152/1152 [==============================] - 65s 56ms/step - loss: 1.2238 - accuracy: 0.5339\n",
      "Epoch 41/100\n",
      "1152/1152 [==============================] - 52s 45ms/step - loss: 1.2355 - accuracy: 0.5330\n",
      "Epoch 42/100\n",
      "1152/1152 [==============================] - 135s 118ms/step - loss: 1.2308 - accuracy: 0.5339\n",
      "Epoch 43/100\n",
      "1152/1152 [==============================] - 49s 42ms/step - loss: 1.2339 - accuracy: 0.5339\n",
      "Epoch 44/100\n",
      "1152/1152 [==============================] - 53s 46ms/step - loss: 1.2357 - accuracy: 0.5339\n",
      "Epoch 45/100\n",
      "1152/1152 [==============================] - 40s 35ms/step - loss: 1.2338 - accuracy: 0.5321\n",
      "Epoch 46/100\n",
      "1152/1152 [==============================] - 42s 36ms/step - loss: 1.2369 - accuracy: 0.5330\n",
      "Epoch 47/100\n",
      "1152/1152 [==============================] - 40s 35ms/step - loss: 1.2380 - accuracy: 0.5339\n",
      "Epoch 48/100\n",
      "1152/1152 [==============================] - 50s 44ms/step - loss: 1.2388 - accuracy: 0.5339\n",
      "Epoch 49/100\n",
      "1152/1152 [==============================] - 70s 61ms/step - loss: 1.2287 - accuracy: 0.5339\n",
      "Epoch 50/100\n",
      "1152/1152 [==============================] - 63s 55ms/step - loss: 1.2345 - accuracy: 0.5339\n",
      "Epoch 51/100\n",
      "1152/1152 [==============================] - 48s 42ms/step - loss: 1.2312 - accuracy: 0.5339\n",
      "Epoch 52/100\n",
      "1152/1152 [==============================] - 57s 49ms/step - loss: 1.2320 - accuracy: 0.5330\n",
      "Epoch 53/100\n",
      "1152/1152 [==============================] - 65s 56ms/step - loss: 1.2359 - accuracy: 0.5347\n",
      "Epoch 54/100\n",
      "1152/1152 [==============================] - 62s 54ms/step - loss: 1.2312 - accuracy: 0.5339\n",
      "Epoch 55/100\n",
      "1152/1152 [==============================] - 53s 46ms/step - loss: 1.2309 - accuracy: 0.5339\n",
      "Epoch 56/100\n",
      "1152/1152 [==============================] - 78s 67ms/step - loss: 1.2290 - accuracy: 0.5278\n",
      "Epoch 57/100\n",
      "1152/1152 [==============================] - 59s 51ms/step - loss: 1.2341 - accuracy: 0.5339\n",
      "Epoch 58/100\n",
      "1152/1152 [==============================] - 57s 49ms/step - loss: 1.2331 - accuracy: 0.5339\n",
      "Epoch 59/100\n",
      "1152/1152 [==============================] - 55s 48ms/step - loss: 1.2277 - accuracy: 0.5304\n",
      "Epoch 60/100\n",
      "1152/1152 [==============================] - 53s 46ms/step - loss: 1.2317 - accuracy: 0.5339\n",
      "Epoch 61/100\n",
      "1152/1152 [==============================] - 71s 62ms/step - loss: 1.2419 - accuracy: 0.5312\n",
      "Epoch 62/100\n",
      "1152/1152 [==============================] - 65s 57ms/step - loss: 1.2261 - accuracy: 0.5339\n",
      "Epoch 63/100\n",
      "1152/1152 [==============================] - 46s 40ms/step - loss: 1.2295 - accuracy: 0.5339\n",
      "Epoch 64/100\n",
      "1152/1152 [==============================] - 65s 57ms/step - loss: 1.2297 - accuracy: 0.5339\n",
      "Epoch 65/100\n",
      "1152/1152 [==============================] - 78s 68ms/step - loss: 1.2290 - accuracy: 0.5339\n",
      "Epoch 66/100\n",
      "1152/1152 [==============================] - 85s 74ms/step - loss: 1.2321 - accuracy: 0.5339\n",
      "Epoch 67/100\n",
      "1152/1152 [==============================] - 71s 62ms/step - loss: 1.2282 - accuracy: 0.5321\n",
      "Epoch 68/100\n",
      "1152/1152 [==============================] - 83s 72ms/step - loss: 1.2361 - accuracy: 0.5339\n",
      "Epoch 69/100\n",
      "1152/1152 [==============================] - 82s 71ms/step - loss: 1.2343 - accuracy: 0.5339\n",
      "Epoch 70/100\n",
      "1152/1152 [==============================] - 60s 52ms/step - loss: 1.2324 - accuracy: 0.5339\n",
      "Epoch 71/100\n",
      "1152/1152 [==============================] - 45s 39ms/step - loss: 1.2304 - accuracy: 0.5321\n",
      "Epoch 72/100\n",
      "1152/1152 [==============================] - 54s 47ms/step - loss: 1.2266 - accuracy: 0.5339\n",
      "Epoch 73/100\n",
      "1152/1152 [==============================] - 45s 39ms/step - loss: 1.2583 - accuracy: 0.5208\n",
      "Epoch 74/100\n",
      "1152/1152 [==============================] - 40s 35ms/step - loss: 1.2289 - accuracy: 0.5356\n",
      "Epoch 75/100\n",
      "1152/1152 [==============================] - 44s 38ms/step - loss: 1.2392 - accuracy: 0.5339\n",
      "Epoch 76/100\n",
      "1152/1152 [==============================] - 37s 32ms/step - loss: 1.2330 - accuracy: 0.5339\n",
      "Epoch 77/100\n",
      "1152/1152 [==============================] - 63s 55ms/step - loss: 1.2320 - accuracy: 0.5339\n",
      "Epoch 78/100\n",
      "1152/1152 [==============================] - 49s 43ms/step - loss: 1.2314 - accuracy: 0.5330\n",
      "Epoch 79/100\n",
      "1152/1152 [==============================] - 60s 52ms/step - loss: 1.2296 - accuracy: 0.5339\n",
      "Epoch 80/100\n",
      "1152/1152 [==============================] - 72s 63ms/step - loss: 1.2331 - accuracy: 0.5339\n",
      "Epoch 81/100\n",
      "1152/1152 [==============================] - 48s 42ms/step - loss: 1.2309 - accuracy: 0.5339\n",
      "Epoch 82/100\n",
      "1152/1152 [==============================] - 52s 45ms/step - loss: 1.2298 - accuracy: 0.5339\n",
      "Epoch 83/100\n",
      "1152/1152 [==============================] - 55s 48ms/step - loss: 1.2315 - accuracy: 0.5339\n",
      "Epoch 84/100\n",
      "1152/1152 [==============================] - 63s 55ms/step - loss: 1.2274 - accuracy: 0.5339\n",
      "Epoch 85/100\n",
      "1152/1152 [==============================] - 49s 42ms/step - loss: 1.2293 - accuracy: 0.5339\n",
      "Epoch 86/100\n",
      "1152/1152 [==============================] - 62s 54ms/step - loss: 1.2292 - accuracy: 0.5330\n",
      "Epoch 87/100\n",
      "1152/1152 [==============================] - 46s 40ms/step - loss: 1.2284 - accuracy: 0.5339\n",
      "Epoch 88/100\n",
      "1152/1152 [==============================] - 52s 45ms/step - loss: 1.2229 - accuracy: 0.5339\n",
      "Epoch 89/100\n",
      "1152/1152 [==============================] - 81s 71ms/step - loss: 1.2299 - accuracy: 0.5339\n",
      "Epoch 90/100\n",
      "1152/1152 [==============================] - 65s 56ms/step - loss: 1.2259 - accuracy: 0.5339\n",
      "Epoch 91/100\n",
      "1152/1152 [==============================] - 58s 50ms/step - loss: 1.2289 - accuracy: 0.5339\n",
      "Epoch 92/100\n",
      "1152/1152 [==============================] - 72s 62ms/step - loss: 1.2319 - accuracy: 0.5339\n",
      "Epoch 93/100\n",
      "1152/1152 [==============================] - 41s 35ms/step - loss: 1.2287 - accuracy: 0.5339\n",
      "Epoch 94/100\n",
      "1152/1152 [==============================] - 48s 42ms/step - loss: 1.2298 - accuracy: 0.5339\n",
      "Epoch 95/100\n",
      "1152/1152 [==============================] - 46s 40ms/step - loss: 1.2283 - accuracy: 0.5339\n",
      "Epoch 96/100\n",
      "1152/1152 [==============================] - 40s 35ms/step - loss: 1.2260 - accuracy: 0.5339\n",
      "Epoch 97/100\n",
      "1152/1152 [==============================] - 33s 29ms/step - loss: 1.2267 - accuracy: 0.5339\n",
      "Epoch 98/100\n",
      "1152/1152 [==============================] - 28s 24ms/step - loss: 1.2257 - accuracy: 0.5339\n",
      "Epoch 99/100\n",
      "1152/1152 [==============================] - 23s 20ms/step - loss: 1.2273 - accuracy: 0.5339\n",
      "Epoch 100/100\n",
      "1152/1152 [==============================] - 25s 22ms/step - loss: 1.2319 - accuracy: 0.5339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ancao/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ancao/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ancao/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ancao/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ancao/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ancao/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ancao/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ancao/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ancao/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ancao/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/ancao/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/ancao/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ancao/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ancao/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ancao/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ancao/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ancao/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ancao/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ancao/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ancao/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ancao/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ancao/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ancao/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Accuracy: 0.5338541666666666\n",
      "Average Train AUC Score: 0.49762979188361056\n",
      "Average Train MCC Score: 0.0 \n",
      "\n",
      "\n",
      "Average Train Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    artifact    0.00000   0.00000   0.00000       128\n",
      "    extrahls    0.00000   0.00000   0.00000        41\n",
      "  extrastole    0.00000   0.00000   0.00000        70\n",
      "      murmur    0.00000   0.00000   0.00000       298\n",
      "      normal    0.53385   1.00000   0.69610       615\n",
      "\n",
      "    accuracy                        0.53385      1152\n",
      "   macro avg    0.10677   0.20000   0.13922      1152\n",
      "weighted avg    0.28500   0.53385   0.37161      1152\n",
      "\n",
      "Average Test Accuracy: 0.532871972318339\n",
      "Average Test AUC Score: 0.4922549167518942\n",
      "Average Test MCC Score: 0.0 \n",
      "\n",
      "\n",
      "Average Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    artifact    0.00000   0.00000   0.00000        32\n",
      "    extrahls    0.00000   0.00000   0.00000        10\n",
      "  extrastole    0.00000   0.00000   0.00000        18\n",
      "      murmur    0.00000   0.00000   0.00000        75\n",
      "      normal    0.53287   1.00000   0.69526       154\n",
      "\n",
      "    accuracy                        0.53287       289\n",
      "   macro avg    0.10657   0.20000   0.13905       289\n",
      "weighted avg    0.28395   0.53287   0.37048       289\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Audio processing\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, matthews_corrcoef, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle, class_weight\n",
    "\n",
    "# Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Flatten, BatchNormalization, Reshape\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "dataset = []\n",
    "\n",
    "for folder in [\"Heartbeat_Sounds/set_a/**\",\"Heartbeat_Sounds/set_b/**\"]:\n",
    "    for filename in glob.iglob(folder):\n",
    "        if os.path.exists(filename):\n",
    "            label = os.path.basename(filename).split(\"_\")[0]\n",
    "            duration = librosa.get_duration(filename=filename)\n",
    "            # skip audio smaller than 3 secs\n",
    "            if duration>=3:\n",
    "                slice_size = 3\n",
    "                iterations = int((duration-slice_size)/(slice_size-1))\n",
    "                iterations += 1\n",
    "#                 initial_offset = (duration % slice_size)/2\n",
    "                initial_offset = (duration - ((iterations*(slice_size-1))+1))/2\n",
    "                if label not in [\"Aunlabelledtest\", \"Bunlabelledtest\"]:\n",
    "                    for i in range(iterations):\n",
    "                        offset = initial_offset + i*(slice_size-1)\n",
    "                        \n",
    "                        dataset.append({\n",
    "                                \"filename\": filename,\n",
    "                                \"label\": label,\n",
    "                                \"offset\": offset\n",
    "                            })\n",
    "                       \n",
    "                        \n",
    "dataset = pd.DataFrame(dataset)\n",
    "dataset = shuffle(dataset, random_state=42)\n",
    "dataset.info()\n",
    "\n",
    "# Function to extract features\n",
    "def extract_features(audio_path, offset):\n",
    "    y, sr = librosa.load(audio_path, offset=offset, duration=3)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "    # Reshape for CNN input\n",
    "    mfccs = np.expand_dims(mfccs, axis=-1)\n",
    "    return mfccs\n",
    "\n",
    "# Extract features for all data points\n",
    "x_data = []\n",
    "for idx in tqdm(range(len(dataset))):\n",
    "    mfccs = extract_features(dataset.filename.iloc[idx], dataset.offset.iloc[idx])\n",
    "    # Reshape the 2D array to 3D array\n",
    "    mfccs = mfccs.reshape((mfccs.shape[0], mfccs.shape[1], 1))\n",
    "    x_data.append(mfccs)\n",
    "\n",
    "# Convert to numpy array\n",
    "x_data = np.asarray(x_data)\n",
    "\n",
    "\n",
    "# Encode Labels\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataset.label)\n",
    "y_data = encoder.transform(dataset.label)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = class_weight.compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_data), y=y_data)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_data_one_hot = to_categorical(y_data)\n",
    "\n",
    "# Initialize StratifiedKFold with train_size and test_size\n",
    "kfold = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize lists to store results for each fold\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "train_auc_scores = []\n",
    "test_auc_scores = []\n",
    "train_mcc_scores = []\n",
    "test_mcc_scores = []\n",
    "train_conf_matrices = []\n",
    "test_conf_matrices = []\n",
    "train_class_reports = []\n",
    "test_class_reports = []\n",
    "cm_test_normalized = []\n",
    "report_test_list = []\n",
    "cm_test_normalized_list = []\n",
    "\n",
    "# Open the common results file in 'w' mode to overwrite existing content\n",
    "with open('results_heartSound/all_folds_2dcnn5_results_kethop.txt', 'w') as common_file:\n",
    "    # Split the indices instead of the dataset\n",
    "    for fold, (train_index, test_index) in enumerate(kfold.split(x_data, y_data), 1):\n",
    "        x_train_fold, x_test_fold = x_data[train_index], x_data[test_index]\n",
    "        y_train_fold, y_test_fold = y_data_one_hot[train_index], y_data_one_hot[test_index]\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        # First block of conv.\n",
    "        model.add(Conv2D(filters=32, kernel_size=2, input_shape=(x_train_fold.shape[1], x_train_fold.shape[2], x_train_fold.shape[3]), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=2))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        # Second block of conv.\n",
    "        model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        # Third block of conv.\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        # LSTM layer\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Reshape((-1, 64)))  # Reshape for LSTM\n",
    "        model.add(LSTM(64, return_sequences=False))\n",
    "\n",
    "        model.add(Dense(len(encoder.classes_), activation='softmax'))\n",
    "\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        your_epochs = 100  # You can choose an appropriate number of epochs\n",
    "        your_batch_size = 1  # You can choose an appropriate batch size\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(x_train_fold, y_train_fold, epochs=your_epochs, batch_size=your_batch_size, verbose=1)\n",
    "\n",
    "        # Evaluate on train and test sets\n",
    "        y_pred_train = model.predict(x_train_fold)\n",
    "        y_pred_test = model.predict(x_test_fold)\n",
    "        \n",
    "        # Generate classification report and confusion matrix for test set\n",
    "        y_pred_test_labels = np.argmax(y_pred_test, axis=1)\n",
    "        report_test = classification_report(np.argmax(y_test_fold, axis=1), y_pred_test_labels, output_dict=True)\n",
    "\n",
    "\n",
    "        # Calculate metrics for train set\n",
    "        train_accuracy = accuracy_score(np.argmax(y_train_fold, axis=1), np.argmax(y_pred_train, axis=1))\n",
    "        train_auc = roc_auc_score(y_train_fold, y_pred_train, multi_class='ovr')\n",
    "        train_mcc = matthews_corrcoef(np.argmax(y_train_fold, axis=1), np.argmax(y_pred_train, axis=1))\n",
    "        train_cm = confusion_matrix(np.argmax(y_train_fold, axis=1), np.argmax(y_pred_train, axis=1))\n",
    "        train_class_report = classification_report(np.argmax(y_train_fold, axis=1), np.argmax(y_pred_train, axis=1),\n",
    "                                                   target_names=encoder.classes_)\n",
    "\n",
    "        # Calculate metrics for test set\n",
    "        test_accuracy = accuracy_score(np.argmax(y_test_fold, axis=1), np.argmax(y_pred_test, axis=1))\n",
    "        test_auc = roc_auc_score(y_test_fold, y_pred_test, multi_class='ovr')\n",
    "        test_mcc = matthews_corrcoef(np.argmax(y_test_fold, axis=1), np.argmax(y_pred_test, axis=1))\n",
    "        test_cm = confusion_matrix(np.argmax(y_test_fold, axis=1), np.argmax(y_pred_test, axis=1))\n",
    "        test_class_report = classification_report(np.argmax(y_test_fold, axis=1), np.argmax(y_pred_test, axis=1),\n",
    "                                                  target_names=encoder.classes_)\n",
    "\n",
    "        # Inside the loop where you append accuracies to lists\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "\n",
    "        # Calculate std for train and test accuracies\n",
    "        train_accuracy_std = np.std(train_accuracies)\n",
    "        test_accuracy_std = np.std(test_accuracies)\n",
    "\n",
    "\n",
    "        # Save results to the common text file for both train and test sets\n",
    "        common_file.write(f'Fold {fold} Results:\\n')\n",
    "        common_file.write(f'Train Accuracy: {train_accuracy} (std: {train_accuracy_std})\\n')\n",
    "        common_file.write(f'Train AUC Score: {train_auc}\\n')\n",
    "        common_file.write(f'Train MCC Score: {train_mcc}\\n\\n')\n",
    "        common_file.write('Train Confusion Matrix:\\n')\n",
    "        common_file.write(str(train_cm))\n",
    "        common_file.write('\\n\\nTrain Classification Report:\\n')\n",
    "        common_file.write(train_class_report)\n",
    "\n",
    "        common_file.write(f'\\n\\nTest Accuracy: {test_accuracy} (std: {test_accuracy_std})\\n')\n",
    "        common_file.write(f'Test AUC Score: {test_auc}\\n')\n",
    "        common_file.write(f'Test MCC Score: {test_mcc}\\n\\n')\n",
    "        common_file.write('Test Confusion Matrix:\\n')\n",
    "        common_file.write(str(test_cm))\n",
    "        common_file.write('\\n\\nTest Classification Report:\\n')\n",
    "        common_file.write(test_class_report)\n",
    "        \n",
    "        # Print a separator between folds\n",
    "        common_file.write(\"\\n\" + \"=\"*40 + \"\\n\")\n",
    "        \n",
    "        # Calculate average metrics for train set\n",
    "        avg_train_accuracy = np.mean(train_accuracies)\n",
    "        avg_train_auc = np.mean(train_auc_scores)\n",
    "        avg_train_mcc = np.mean(train_mcc_scores)\n",
    "        avg_train_conf_matrix = np.mean(train_conf_matrices, axis=0)  # Average confusion matrix\n",
    "\n",
    "        # Convert continuous probabilities to class labels using argmax\n",
    "        y_pred_train_class = np.argmax(y_pred_train, axis=1)\n",
    "\n",
    "        # Calculate average metrics for test set\n",
    "        avg_test_accuracy = np.mean(test_accuracies)\n",
    "        avg_test_auc = np.mean(test_auc_scores)\n",
    "        avg_test_mcc = np.mean(test_mcc_scores)\n",
    "        avg_test_conf_matrix = np.mean(test_conf_matrices, axis=0)  # Average confusion matrix\n",
    "\n",
    "        # Convert continuous probabilities to class labels using argmax\n",
    "        y_pred_test_class = np.argmax(y_pred_test, axis=1)\n",
    "        \n",
    "        # Calculate average results for train set\n",
    "        avg_train_class_report = classification_report(np.argmax(y_train_fold, axis=1), y_pred_train_class, target_names=encoder.classes_)\n",
    "\n",
    "        # Calculate average results for test set\n",
    "        avg_test_class_report = classification_report(np.argmax(y_test_fold, axis=1), y_pred_test_class, target_names=encoder.classes_)\n",
    "\n",
    "        # Inside the loop where you plot confusion matrices\n",
    "        plt.figure()\n",
    "        train_cm = confusion_matrix(np.argmax(y_train_fold, axis=1), y_pred_train.argmax(axis=1))\n",
    "\n",
    "        # Round each value in the confusion matrix to 5 decimal places\n",
    "        rounded_train_cm = np.round(train_cm / np.sum(train_cm, axis=1)[:, np.newaxis], 5)\n",
    "\n",
    "        sns.heatmap(rounded_train_cm, annot=True, fmt='.5f', cmap='Blues', xticklabels=encoder.classes_, yticklabels=encoder.classes_)\n",
    "        plt.title(f'Train Confusion Matrix - Fold {fold}')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.savefig(f'KH/train_confusion_matrix_fold_{fold}.png')\n",
    "        plt.close()\n",
    "\n",
    "        # Inside the loop where you plot confusion matrices\n",
    "        plt.figure()\n",
    "        test_cm = confusion_matrix(np.argmax(y_test_fold, axis=1), y_pred_test.argmax(axis=1))\n",
    "\n",
    "        # Round each value in the confusion matrix to 5 decimal places\n",
    "        rounded_test_cm = np.round(test_cm / np.sum(test_cm, axis=1)[:, np.newaxis], 5)\n",
    "\n",
    "        sns.heatmap(rounded_test_cm, annot=True, fmt='.5f', cmap='Blues', xticklabels=encoder.classes_, yticklabels=encoder.classes_)\n",
    "        plt.title(f'Test Confusion Matrix - Fold {fold}')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.savefig(f'KH/test_confusion_matrix_fold_{fold}.png')\n",
    "        plt.close()\n",
    "\n",
    "        # Inside the loop where you append results to lists\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        train_auc_scores.append(train_auc)\n",
    "        test_auc_scores.append(test_auc)\n",
    "        train_mcc_scores.append(train_mcc)\n",
    "        test_mcc_scores.append(test_mcc)\n",
    "        train_conf_matrices.append(train_cm)\n",
    "        test_conf_matrices.append(test_cm)\n",
    "        train_class_reports.append(train_class_report)\n",
    "        test_class_reports.append(test_class_report)\n",
    "        \n",
    "        # Print a separator between folds\n",
    "        common_file.write(\"\\n\" + \"=\"*40 + \"\\n\")\n",
    "        \n",
    "        # Append classification report and confusion matrix to lists\n",
    "        report_test_list.append(report_test)\n",
    "        cm_test_normalized_list.append(cm_test_normalized)\n",
    "\n",
    "    # Calculate average metrics for train set\n",
    "    avg_train_accuracy = np.mean(train_accuracies)\n",
    "    avg_train_auc = np.mean(train_auc_scores)\n",
    "    avg_train_mcc = np.mean(train_mcc_scores)\n",
    "\n",
    "    # Reshape y_train_fold to (num_samples, num_classes)\n",
    "    y_train_fold_reshaped = to_categorical(y_train_fold, num_classes=len(encoder.classes_))\n",
    "\n",
    "    # Convert predictions to one-hot encoding\n",
    "    y_pred_train_one_hot = to_categorical(np.argmax(y_pred_train, axis=1), num_classes=len(encoder.classes_))\n",
    "\n",
    "    # Calculate average confusion matrix for train set\n",
    "    avg_train_conf_matrix = np.mean(train_conf_matrices, axis=0).astype(int)\n",
    "\n",
    "\n",
    "    # Calculate average classification report for train set\n",
    "    avg_train_class_report = classification_report(\n",
    "        np.argmax(y_train_fold, axis=1), \n",
    "        np.argmax(y_pred_train_one_hot, axis=1), \n",
    "        target_names=encoder.classes_, \n",
    "        digits=5\n",
    "    )\n",
    "    \n",
    "\n",
    "    # Calculate average metrics for test set\n",
    "    avg_test_accuracy = np.mean(test_accuracies)\n",
    "    avg_test_auc = np.mean(test_auc_scores)\n",
    "    avg_test_mcc = np.mean(test_mcc_scores)\n",
    "\n",
    "    # Reshape y_test_fold to (num_samples, num_classes)\n",
    "    y_test_fold_reshaped = to_categorical(y_test_fold, num_classes=len(encoder.classes_))\n",
    "\n",
    "    # Convert predictions to one-hot encoding\n",
    "    y_pred_test_one_hot = to_categorical(np.argmax(y_pred_test, axis=1), num_classes=len(encoder.classes_))\n",
    "\n",
    "    # Calculate average confusion matrix for test set\n",
    "    avg_test_conf_matrix = np.mean(test_conf_matrices, axis=0).astype(int)\n",
    "\n",
    "    # Calculate average classification report for test set\n",
    "    avg_test_class_report = classification_report(\n",
    "        np.argmax(y_test_fold, axis=1), \n",
    "        np.argmax(y_pred_test_one_hot, axis=1), \n",
    "        target_names=encoder.classes_, \n",
    "        digits=5\n",
    "    )\n",
    "\n",
    "    # Inside the loop where you plot the average confusion matrix for the test set\n",
    "    avg_cm_test_normalized = np.mean(cm_test_normalized_list, axis=0)\n",
    "    plt.figure()\n",
    "\n",
    "    avg_test_cm = confusion_matrix(np.argmax(y_test_fold, axis=1), np.argmax(y_pred_test, axis=1))\n",
    "\n",
    "    # Normalize the confusion matrix by dividing each value by the sum of its row\n",
    "    normalized_avg_test_cm = avg_test_cm / avg_test_cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    # Plot confusion matrix for the average test set\n",
    "    plt.figure()\n",
    "    sns.heatmap(normalized_avg_test_cm, annot=True, fmt='.5f', cmap='Blues', xticklabels=encoder.classes_, yticklabels=encoder.classes_)\n",
    "    plt.title(f'Average Test Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.savefig('KH/average_test_confusion_matrix.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Save average results to the common text file\n",
    "    common_file.write(\"\\n\" + \"=\"*40 + \"\\n\")\n",
    "    common_file.write(f'Average Test Accuracy: {avg_test_accuracy:.5f} (std: {np.std(test_accuracies):.5f})\\n')\n",
    "    common_file.write(f'Average Test AUC Score: {avg_test_auc:.5f}\\n')\n",
    "    common_file.write(f'Average Test MCC Score: {avg_test_mcc:.5f}\\n\\n')\n",
    "    common_file.write('Average Test Confusion Matrix:\\n')\n",
    "    common_file.write(str(avg_cm_test_normalized.round(5).astype(int)))  # Display confusion matrix with 5 decimal places\n",
    "    common_file.write(\"\\n\\nAverage Test Classification Report:\\n\")\n",
    "    common_file.write(str(avg_test_class_report))\n",
    "\n",
    "\n",
    "    # Print and write the average results to the common text file\n",
    "    common_file.write(\"\\n\" + \"=\"*40 + \"\\n\")\n",
    "    common_file.write(f'Average Test Accuracy: {avg_test_accuracy:.5f} (std: {np.std(test_accuracies):.5f})\\n')\n",
    "    common_file.write(f'Average Test AUC Score: {avg_test_auc:.5f}\\n')\n",
    "    common_file.write(f'Average Test MCC Score: {avg_test_mcc:.5f}\\n\\n')\n",
    "    common_file.write('Average Test Confusion Matrix:\\n')\n",
    "    common_file.write(str(avg_cm_test_normalized.round(5).astype(int)))  # Display confusion matrix with 5 decimal places\n",
    "    common_file.write(\"\\n\\nAverage Test Classification Report:\\n\")\n",
    "    common_file.write(str(avg_test_class_report))\n",
    "\n",
    "\n",
    "    # Print and write the average results to the common text file\n",
    "    common_file.write(\"\\n\" + \"=\"*40 + \"\\n\")\n",
    "    common_file.write(f'Average Train Accuracy: {avg_train_accuracy} (std: {np.std(train_accuracies)})\\n')\n",
    "    common_file.write(f'Average Train AUC Score: {avg_train_auc}\\n')\n",
    "    common_file.write(f'Average Train MCC Score: {avg_train_mcc}\\n\\n')\n",
    "    common_file.write('Average Train Confusion Matrix:\\n')\n",
    "    common_file.write(str(avg_train_conf_matrix.astype(int)))\n",
    "    common_file.write(\"\\n\\nAverage Train Classification Report:\\n\")\n",
    "    common_file.write(str(avg_train_class_report))\n",
    "\n",
    "    common_file.write(\"\\n\" + \"=\"*40 + \"\\n\")\n",
    "    common_file.write(f'Average Test Accuracy: {avg_test_accuracy} (std: {np.std(test_accuracies)})\\n')\n",
    "    common_file.write(f'Average Test AUC Score: {avg_test_auc}\\n')\n",
    "    common_file.write(f'Average Test MCC Score: {avg_test_mcc}\\n\\n')\n",
    "    common_file.write('Average Test Confusion Matrix:\\n')\n",
    "    common_file.write(str(avg_test_conf_matrix.astype(int)))\n",
    "    common_file.write(\"\\n\\nAverage Test Classification Report:\\n\")\n",
    "    common_file.write(str(avg_test_class_report))\n",
    "        \n",
    "    # Print average results for train set\n",
    "    print(f'Average Train Accuracy: {avg_train_accuracy}')\n",
    "    print(f'Average Train AUC Score: {avg_train_auc}')\n",
    "    print(f'Average Train MCC Score: {avg_train_mcc} \\n')\n",
    "    print(\"\\nAverage Train Classification Report:\")\n",
    "    print(avg_train_class_report)\n",
    "\n",
    "    # Print average results for test set\n",
    "    print(f'Average Test Accuracy: {avg_test_accuracy}')\n",
    "    print(f'Average Test AUC Score: {avg_test_auc}')\n",
    "    print(f'Average Test MCC Score: {avg_test_mcc} \\n')\n",
    "    print(\"\\nAverage Test Classification Report:\")\n",
    "    print(avg_test_class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09877e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đọc dữ liệu từ tệp CSV\n",
    "data = pd.read_csv('heartbeat_sounds')\n",
    "\n",
    "# Lặp qua từng hàng và tạo trích dẫn BibTeX\n",
    "with open('heartbeat_sounds.bib', 'w') as bibfile:\n",
    "    for index, row in data.iterrows():\n",
    "        title = row['Title']\n",
    "        author = row['Author']\n",
    "        year = row['Year']\n",
    "        url = row['Url']\n",
    "        \n",
    "        bibfile.write(f\"@misc{{{author}{year},\\n\")\n",
    "        bibfile.write(f\"  title = {{{title}}},\\n\")\n",
    "        bibfile.write(f\"  author = {{{author}}},\\n\")\n",
    "        bibfile.write(f\"  year = {{{year}}},\\n\")\n",
    "        bibfile.write(f\"  url = {{{url}}}\\n\")\n",
    "        bibfile.write(\"}\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b66527",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
